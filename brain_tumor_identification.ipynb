{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize data into tumor/nontumor and split into train, val, and test sets\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.makedirs('tumor', exist_ok=True)\n",
    "os.makedirs('nontumor', exist_ok=True)\n",
    "\n",
    "for tumor_dir in ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor']:\n",
    "    for img in os.listdir(tumor_dir):\n",
    "        shutil.move(os.path.join(tumor_dir, img), 'tumor')\n",
    "\n",
    "for img in os.listdir('normal'):\n",
    "    shutil.move(os.path.join('normal', img), 'nontumor')\n",
    "\n",
    "shutil.rmtree('glioma_tumor')\n",
    "shutil.rmtree('meningioma_tumor')\n",
    "shutil.rmtree('pituitary_tumor')\n",
    "shutil.rmtree('normal')\n",
    "\n",
    "def split_data(source_dir, dest_dir, split_ratios=(0.8, 0.1, 0.1)):\n",
    "    files = os.listdir(source_dir)\n",
    "    train_files, temp_files = train_test_split(files, train_size=split_ratios[0], random_state=42)\n",
    "    val_files, test_files = train_test_split(temp_files, train_size=split_ratios[1]/(split_ratios[1] + split_ratios[2]), random_state=42)\n",
    "    \n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(dest_dir, 'train', os.path.basename(source_dir), file))\n",
    "    for file in val_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(dest_dir, 'val', os.path.basename(source_dir), file))\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(dest_dir, 'test', os.path.basename(source_dir), file))\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(split, 'tumor'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split, 'nontumor'), exist_ok=True)\n",
    "\n",
    "split_data('tumor', '.')\n",
    "split_data('nontumor', '.')\n",
    "\n",
    "shutil.rmtree('tumor')\n",
    "shutil.rmtree('nontumor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set - Tumor images: 2126, Nontumor images: 350\n",
      "Val set - Tumor images: 266, Nontumor images: 44\n",
      "Test set - Tumor images: 266, Nontumor images: 44\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to count the number of files in each directory\n",
    "def count_files(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])\n",
    "\n",
    "# Print the number of images in each category for each dataset\n",
    "for split in ['train', 'val', 'test']:\n",
    "    tumor_count = count_files(os.path.join(split, 'tumor'))\n",
    "    nontumor_count = count_files(os.path.join(split, 'nontumor'))\n",
    "    print(f\"{split.capitalize()} set - Tumor images: {tumor_count}, Nontumor images: {nontumor_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2476 images belonging to 2 classes.\n",
      "Found 310 images belonging to 2 classes.\n",
      "Found 310 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data using ImageDataGenerator with augmentation for training and normalization for validation/test\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    'val',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    'test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
