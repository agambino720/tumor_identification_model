{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (Binary Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the data into tumor/nontumor and splitting it into train, val, and test sets\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.makedirs('tumor', exist_ok=True)\n",
    "os.makedirs('nontumor', exist_ok=True)\n",
    "\n",
    "for tumor_dir in ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor']:\n",
    "    for img in os.listdir(tumor_dir):\n",
    "        shutil.move(os.path.join(tumor_dir, img), 'tumor')\n",
    "\n",
    "for img in os.listdir('normal'):\n",
    "    shutil.move(os.path.join('normal', img), 'nontumor')\n",
    "\n",
    "shutil.rmtree('glioma_tumor')\n",
    "shutil.rmtree('meningioma_tumor')\n",
    "shutil.rmtree('pituitary_tumor')\n",
    "shutil.rmtree('normal')\n",
    "\n",
    "def split_data(source_dir, dest_dir, split_ratios=(0.8, 0.1, 0.1)):\n",
    "    files = os.listdir(source_dir)\n",
    "    train_files, temp_files = train_test_split(files, train_size=split_ratios[0], random_state=42)\n",
    "    val_files, test_files = train_test_split(temp_files, train_size=split_ratios[1]/(split_ratios[1] + split_ratios[2]), random_state=42)\n",
    "    \n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(dest_dir, 'train', os.path.basename(source_dir), file))\n",
    "    for file in val_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(dest_dir, 'val', os.path.basename(source_dir), file))\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(dest_dir, 'test', os.path.basename(source_dir), file))\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(split, 'tumor'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split, 'nontumor'), exist_ok=True)\n",
    "\n",
    "split_data('tumor', '.')\n",
    "split_data('nontumor', '.')\n",
    "\n",
    "shutil.rmtree('tumor')\n",
    "shutil.rmtree('nontumor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set - Tumor images: 2126, Nontumor images: 350\n",
      "Val set - Tumor images: 266, Nontumor images: 44\n",
      "Test set - Tumor images: 266, Nontumor images: 44\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of files in each directory and printing the number of images per category in each dataset\n",
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    tumor_count = count_files(os.path.join(split, 'tumor'))\n",
    "    nontumor_count = count_files(os.path.join(split, 'nontumor'))\n",
    "    print(f\"{split.capitalize()} set - Tumor images: {tumor_count}, Nontumor images: {nontumor_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2476 images belonging to 2 classes.\n",
      "Found 310 images belonging to 2 classes.\n",
      "Found 310 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the data using ImageDataGenerator with augmentation for training and normalization for validation/test\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    'val',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    'test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (Binary Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - 180s 2s/step - loss: 0.4620 - accuracy: 0.8538 - val_loss: 0.4434 - val_accuracy: 0.8581\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 166s 2s/step - loss: 0.4164 - accuracy: 0.8586 - val_loss: 0.3669 - val_accuracy: 0.8581\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 163s 2s/step - loss: 0.3338 - accuracy: 0.8595 - val_loss: 0.2735 - val_accuracy: 0.8581\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 155s 2s/step - loss: 0.3145 - accuracy: 0.8574 - val_loss: 0.2881 - val_accuracy: 0.8581\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 155s 2s/step - loss: 0.2847 - accuracy: 0.8704 - val_loss: 0.2322 - val_accuracy: 0.8903\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 150s 2s/step - loss: 0.2527 - accuracy: 0.8724 - val_loss: 0.1949 - val_accuracy: 0.9097\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.2613 - accuracy: 0.8764 - val_loss: 0.1965 - val_accuracy: 0.9097\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.2265 - accuracy: 0.8938 - val_loss: 0.1683 - val_accuracy: 0.9290\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.2221 - accuracy: 0.8998 - val_loss: 0.3253 - val_accuracy: 0.8871\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 150s 2s/step - loss: 0.2052 - accuracy: 0.9059 - val_loss: 0.1843 - val_accuracy: 0.9226\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 150s 2s/step - loss: 0.2179 - accuracy: 0.9035 - val_loss: 0.2514 - val_accuracy: 0.9000\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 151s 2s/step - loss: 0.1870 - accuracy: 0.9192 - val_loss: 0.1444 - val_accuracy: 0.9355\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 152s 2s/step - loss: 0.1813 - accuracy: 0.9212 - val_loss: 0.1386 - val_accuracy: 0.9387\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 151s 2s/step - loss: 0.1944 - accuracy: 0.9148 - val_loss: 0.1860 - val_accuracy: 0.9194\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 151s 2s/step - loss: 0.1783 - accuracy: 0.9188 - val_loss: 0.2447 - val_accuracy: 0.9097\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 151s 2s/step - loss: 0.1653 - accuracy: 0.9253 - val_loss: 0.1075 - val_accuracy: 0.9452\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 152s 2s/step - loss: 0.1543 - accuracy: 0.9321 - val_loss: 0.2438 - val_accuracy: 0.9194\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 153s 2s/step - loss: 0.1513 - accuracy: 0.9301 - val_loss: 0.1193 - val_accuracy: 0.9419\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - 152s 2s/step - loss: 0.1532 - accuracy: 0.9317 - val_loss: 0.1573 - val_accuracy: 0.9355\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - 152s 2s/step - loss: 0.1487 - accuracy: 0.9362 - val_loss: 0.1253 - val_accuracy: 0.9452\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - 153s 2s/step - loss: 0.1390 - accuracy: 0.9382 - val_loss: 0.1258 - val_accuracy: 0.9419\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.1075 - accuracy: 0.9452\n",
      "Validation Loss: 0.10753267258405685\n",
      "Validation Accuracy: 0.9451612830162048\n",
      "10/10 [==============================] - 4s 402ms/step\n",
      "Confusion Matrix:\n",
      "[[  7  37]\n",
      " [ 36 230]]\n",
      "Precision: 0.8614232209737828\n",
      "Recall: 0.8646616541353384\n"
     ]
    }
   ],
   "source": [
    "# Creating, compiling, training, evaluating, and saving a CNN model for binary classification\n",
    "\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import save_model\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "val_loss, val_accuracy = cnn_model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "save_model(cnn_model, 'binary_cnn_model.h5')\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = cnn_model.predict(val_generator)\n",
    "predicted_classes = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "true_classes = val_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "precision = precision_score(true_classes, predicted_classes)\n",
    "recall = recall_score(true_classes, predicted_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Added Layers and Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - 354s 5s/step - loss: 0.4637 - accuracy: 0.8489 - val_loss: 0.4793 - val_accuracy: 0.8581\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 351s 4s/step - loss: 0.4261 - accuracy: 0.8586 - val_loss: 0.3783 - val_accuracy: 0.8581\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 353s 5s/step - loss: 0.3817 - accuracy: 0.8586 - val_loss: 0.2737 - val_accuracy: 0.8581\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.3291 - accuracy: 0.8582 - val_loss: 0.2630 - val_accuracy: 0.8613\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 356s 5s/step - loss: 0.2740 - accuracy: 0.8748 - val_loss: 0.1977 - val_accuracy: 0.9161\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 356s 5s/step - loss: 0.2446 - accuracy: 0.8821 - val_loss: 0.2042 - val_accuracy: 0.9000\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 359s 5s/step - loss: 0.2402 - accuracy: 0.8885 - val_loss: 0.1391 - val_accuracy: 0.9419\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 357s 5s/step - loss: 0.1987 - accuracy: 0.9095 - val_loss: 0.2492 - val_accuracy: 0.9032\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.2075 - accuracy: 0.9019 - val_loss: 0.1316 - val_accuracy: 0.9484\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 357s 5s/step - loss: 0.1723 - accuracy: 0.9221 - val_loss: 0.3290 - val_accuracy: 0.8935\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.1810 - accuracy: 0.9168 - val_loss: 0.1150 - val_accuracy: 0.9419\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 359s 5s/step - loss: 0.1567 - accuracy: 0.9285 - val_loss: 0.1302 - val_accuracy: 0.9419\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 360s 5s/step - loss: 0.1599 - accuracy: 0.9313 - val_loss: 0.1351 - val_accuracy: 0.9419\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 357s 5s/step - loss: 0.1554 - accuracy: 0.9338 - val_loss: 0.1132 - val_accuracy: 0.9581\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 357s 5s/step - loss: 0.1423 - accuracy: 0.9398 - val_loss: 0.1021 - val_accuracy: 0.9484\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 357s 5s/step - loss: 0.1464 - accuracy: 0.9354 - val_loss: 0.1483 - val_accuracy: 0.9355\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 357s 5s/step - loss: 0.1360 - accuracy: 0.9398 - val_loss: 0.1015 - val_accuracy: 0.9516\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.1350 - accuracy: 0.9426 - val_loss: 0.1550 - val_accuracy: 0.9419\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - 356s 5s/step - loss: 0.1231 - accuracy: 0.9451 - val_loss: 0.0991 - val_accuracy: 0.9516\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - 354s 5s/step - loss: 0.1256 - accuracy: 0.9451 - val_loss: 0.1014 - val_accuracy: 0.9484\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.1161 - accuracy: 0.9443 - val_loss: 0.1712 - val_accuracy: 0.9452\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - 356s 5s/step - loss: 0.1244 - accuracy: 0.9426 - val_loss: 0.1314 - val_accuracy: 0.9355\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - 359s 5s/step - loss: 0.1122 - accuracy: 0.9540 - val_loss: 0.0812 - val_accuracy: 0.9613\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - 354s 5s/step - loss: 0.1174 - accuracy: 0.9487 - val_loss: 0.1045 - val_accuracy: 0.9484\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.1036 - accuracy: 0.9564 - val_loss: 0.1109 - val_accuracy: 0.9452\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - 357s 5s/step - loss: 0.1106 - accuracy: 0.9527 - val_loss: 0.1100 - val_accuracy: 0.9516\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - 356s 5s/step - loss: 0.1088 - accuracy: 0.9556 - val_loss: 0.3312 - val_accuracy: 0.9129\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - 357s 5s/step - loss: 0.1166 - accuracy: 0.9499 - val_loss: 0.0891 - val_accuracy: 0.9613\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.0812 - accuracy: 0.9613\n",
      "Validation Loss: 0.08121751993894577\n",
      "Validation Accuracy: 0.9612902998924255\n",
      "10/10 [==============================] - 11s 1s/step\n",
      "Confusion Matrix:\n",
      "[[  3  41]\n",
      " [ 43 223]]\n",
      "Precision: 0.8446969696969697\n",
      "Recall: 0.8383458646616542\n"
     ]
    }
   ],
   "source": [
    "# Creating, compiling, training, evaluating, and saving an enhanced CNN model for binary classification\n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "val_loss, val_accuracy = cnn_model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "save_model(cnn_model, 'enhanced_cnn_model.h5')\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = cnn_model.predict(val_generator)\n",
    "predicted_classes = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "true_classes = val_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "precision = precision_score(true_classes, predicted_classes)\n",
    "recall = recall_score(true_classes, predicted_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Layers and Adjusting Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - 446s 6s/step - loss: 0.4651 - accuracy: 0.8506 - val_loss: 0.4498 - val_accuracy: 0.8581\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 435s 6s/step - loss: 0.4333 - accuracy: 0.8586 - val_loss: 0.4363 - val_accuracy: 0.8581\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 360s 5s/step - loss: 0.3960 - accuracy: 0.8582 - val_loss: 0.3924 - val_accuracy: 0.8581\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 351s 5s/step - loss: 0.3482 - accuracy: 0.8599 - val_loss: 0.2986 - val_accuracy: 0.8581\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 351s 5s/step - loss: 0.3108 - accuracy: 0.8679 - val_loss: 0.2858 - val_accuracy: 0.8548\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 354s 5s/step - loss: 0.2855 - accuracy: 0.8679 - val_loss: 0.3042 - val_accuracy: 0.8548\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 351s 5s/step - loss: 0.2608 - accuracy: 0.8683 - val_loss: 0.1942 - val_accuracy: 0.9097\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 354s 5s/step - loss: 0.2505 - accuracy: 0.8833 - val_loss: 0.1831 - val_accuracy: 0.9194\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 354s 5s/step - loss: 0.2354 - accuracy: 0.8873 - val_loss: 0.1838 - val_accuracy: 0.9194\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 351s 5s/step - loss: 0.2332 - accuracy: 0.8926 - val_loss: 0.2737 - val_accuracy: 0.8871\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.1902 - accuracy: 0.9107 - val_loss: 0.1410 - val_accuracy: 0.9387\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 354s 5s/step - loss: 0.2207 - accuracy: 0.9055 - val_loss: 0.3438 - val_accuracy: 0.8903\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 356s 5s/step - loss: 0.1887 - accuracy: 0.9152 - val_loss: 0.1468 - val_accuracy: 0.9323\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.1805 - accuracy: 0.9156 - val_loss: 0.1662 - val_accuracy: 0.9194\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 353s 5s/step - loss: 0.2003 - accuracy: 0.9148 - val_loss: 0.3341 - val_accuracy: 0.8903\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 355s 5s/step - loss: 0.1882 - accuracy: 0.9160 - val_loss: 0.1543 - val_accuracy: 0.9290\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1410 - accuracy: 0.9387\n",
      "Validation Loss: 0.14099209010601044\n",
      "Validation Accuracy: 0.9387096762657166\n",
      "10/10 [==============================] - 11s 1s/step\n",
      "Confusion Matrix:\n",
      "[[  6  38]\n",
      " [ 35 231]]\n",
      "Precision: 0.8587360594795539\n",
      "Recall: 0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "# Creating, compiling, training, evaluating, and saving a more complex CNN model with adjusted learning rate\n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.00005),  # Reduced learning rate for finer tuning\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "val_loss, val_accuracy = cnn_model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "save_model(cnn_model, 'complex_cnn_model.h5')\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = cnn_model.predict(val_generator)\n",
    "predicted_classes = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "true_classes = val_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "precision = precision_score(true_classes, predicted_classes)\n",
    "recall = recall_score(true_classes, predicted_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 0.1526 - accuracy: 0.9226\n",
      "Test Loss: 0.152609184384346\n",
      "Test Accuracy: 0.9225806593894958\n",
      "10/10 [==============================] - 13s 1s/step\n",
      "Confusion Matrix:\n",
      "[[  7  37]\n",
      " [ 37 229]]\n",
      "Precision: 0.8609022556390977\n",
      "Recall: 0.8609022556390977\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the final model on the test data\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "cnn_model = load_model('complex_cnn_model.h5')\n",
    "\n",
    "test_loss, test_accuracy = cnn_model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "test_generator.reset()\n",
    "predictions = cnn_model.predict(test_generator)\n",
    "predicted_classes = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "precision = precision_score(true_classes, predicted_classes)\n",
    "recall = recall_score(true_classes, predicted_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (Multiple Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glioma_tumor has 901 images\n",
      "meningioma_tumor has 913 images\n",
      "pituitary_tumor has 844 images\n",
      "normal has 438 images\n"
     ]
    }
   ],
   "source": [
    "# Reorganizing images into new directories for multiple classification\n",
    "\n",
    "\n",
    "os.makedirs('glioma_tumor', exist_ok=True)\n",
    "os.makedirs('meningioma_tumor', exist_ok=True)\n",
    "os.makedirs('pituitary_tumor', exist_ok=True)\n",
    "os.makedirs('normal', exist_ok=True)\n",
    "\n",
    "for dataset in ['train', 'val', 'test']:\n",
    "    for category in ['tumor', 'nontumor']:\n",
    "        category_path = os.path.join(dataset, category)\n",
    "        if os.path.exists(category_path):\n",
    "            for img in os.listdir(category_path):\n",
    "                if img.startswith('G'):\n",
    "                    shutil.move(os.path.join(category_path, img), 'glioma_tumor')\n",
    "                elif img.startswith('M'):\n",
    "                    shutil.move(os.path.join(category_path, img), 'meningioma_tumor')\n",
    "                elif img.startswith('P'):\n",
    "                    shutil.move(os.path.join(category_path, img), 'pituitary_tumor')\n",
    "                elif img.startswith('N'):\n",
    "                    shutil.move(os.path.join(category_path, img), 'normal')\n",
    "\n",
    "shutil.rmtree('train')\n",
    "shutil.rmtree('val')\n",
    "shutil.rmtree('test')\n",
    "\n",
    "for dir_name in ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'normal']:\n",
    "    count = len(os.listdir(dir_name))\n",
    "    print(f\"{dir_name} has {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glioma_tumor - Train: 720, Val: 90, Test: 91\n",
      "meningioma_tumor - Train: 730, Val: 91, Test: 92\n",
      "pituitary_tumor - Train: 675, Val: 84, Test: 85\n",
      "normal - Train: 350, Val: 44, Test: 44\n"
     ]
    }
   ],
   "source": [
    "# Performing a train, val, test split \n",
    "\n",
    "def split_data(class_name, split_ratios=(0.8, 0.1, 0.1)):\n",
    "    files = os.listdir(class_name)\n",
    "    train_files, temp_files = train_test_split(files, train_size=split_ratios[0], random_state=42)\n",
    "    val_files, test_files = train_test_split(temp_files, train_size=split_ratios[1]/(split_ratios[1] + split_ratios[2]), random_state=42)\n",
    "\n",
    "    os.makedirs(f'train/{class_name}', exist_ok=True)\n",
    "    os.makedirs(f'val/{class_name}', exist_ok=True)\n",
    "    os.makedirs(f'test/{class_name}', exist_ok=True)\n",
    "\n",
    "    for file in train_files:\n",
    "        shutil.move(os.path.join(class_name, file), os.path.join(f'train/{class_name}', file))\n",
    "    for file in val_files:\n",
    "        shutil.move(os.path.join(class_name, file), os.path.join(f'val/{class_name}', file))\n",
    "    for file in test_files:\n",
    "        shutil.move(os.path.join(class_name, file), os.path.join(f'test/{class_name}', file))\n",
    "\n",
    "    return len(train_files), len(val_files), len(test_files)\n",
    "\n",
    "for class_name in ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'normal']:\n",
    "    train_count, val_count, test_count = split_data(class_name)\n",
    "    print(f\"{class_name} - Train: {train_count}, Val: {val_count}, Test: {test_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2475 images belonging to 4 classes.\n",
      "Found 309 images belonging to 4 classes.\n",
      "Found 312 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setting up image generators for multiclass classification with augmentation for training and normalization for validation & testing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    'val',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    'test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (Multiple Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - 157s 2s/step - loss: 1.3526 - accuracy: 0.3139 - val_loss: 1.3243 - val_accuracy: 0.3754\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 1.3132 - accuracy: 0.3640 - val_loss: 1.3036 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 151s 2s/step - loss: 1.1988 - accuracy: 0.4448 - val_loss: 1.1216 - val_accuracy: 0.5016\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 156s 2s/step - loss: 1.1557 - accuracy: 0.4760 - val_loss: 1.3208 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 165s 2s/step - loss: 1.0772 - accuracy: 0.5147 - val_loss: 0.8991 - val_accuracy: 0.6214\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 159s 2s/step - loss: 1.0283 - accuracy: 0.5410 - val_loss: 0.9856 - val_accuracy: 0.5340\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 1.0033 - accuracy: 0.5568 - val_loss: 0.8566 - val_accuracy: 0.6278\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 0.9515 - accuracy: 0.6044 - val_loss: 0.8601 - val_accuracy: 0.6181\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.9191 - accuracy: 0.6093 - val_loss: 1.0864 - val_accuracy: 0.5307\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.8845 - accuracy: 0.6149 - val_loss: 0.7231 - val_accuracy: 0.7346\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.8674 - accuracy: 0.6339 - val_loss: 0.7642 - val_accuracy: 0.6731\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.8131 - accuracy: 0.6646 - val_loss: 0.8039 - val_accuracy: 0.6731\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 147s 2s/step - loss: 0.7920 - accuracy: 0.6655 - val_loss: 0.8234 - val_accuracy: 0.6214\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 0.7614 - accuracy: 0.6780 - val_loss: 0.7227 - val_accuracy: 0.7087\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.7594 - accuracy: 0.6861 - val_loss: 0.7385 - val_accuracy: 0.6990\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 150s 2s/step - loss: 0.7452 - accuracy: 0.6804 - val_loss: 1.2586 - val_accuracy: 0.5599\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 147s 2s/step - loss: 0.7283 - accuracy: 0.6994 - val_loss: 0.7178 - val_accuracy: 0.7217\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 150s 2s/step - loss: 0.7179 - accuracy: 0.7006 - val_loss: 1.1245 - val_accuracy: 0.5987\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - 152s 2s/step - loss: 0.6816 - accuracy: 0.7087 - val_loss: 0.8295 - val_accuracy: 0.6990\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - 150s 2s/step - loss: 0.6764 - accuracy: 0.7285 - val_loss: 1.1729 - val_accuracy: 0.6117\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 0.6900 - accuracy: 0.7095 - val_loss: 1.1088 - val_accuracy: 0.6214\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - 149s 2s/step - loss: 0.6584 - accuracy: 0.7293 - val_loss: 0.6726 - val_accuracy: 0.7314\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 0.6624 - accuracy: 0.7240 - val_loss: 0.5464 - val_accuracy: 0.7994\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 0.6246 - accuracy: 0.7560 - val_loss: 0.8478 - val_accuracy: 0.6699\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 0.5897 - accuracy: 0.7576 - val_loss: 0.6967 - val_accuracy: 0.7346\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 0.6097 - accuracy: 0.7519 - val_loss: 0.7677 - val_accuracy: 0.7087\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - 148s 2s/step - loss: 0.5977 - accuracy: 0.7531 - val_loss: 0.6030 - val_accuracy: 0.7670\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - 150s 2s/step - loss: 0.6035 - accuracy: 0.7600 - val_loss: 0.7006 - val_accuracy: 0.7217\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.5464 - accuracy: 0.7994\n",
      "Validation Loss: 0.5464129447937012\n",
      "Validation Accuracy: 0.799352765083313\n",
      "10/10 [==============================] - 4s 379ms/step\n",
      "Confusion Matrix:\n",
      "[[15 31 15 29]\n",
      " [27 33 10 21]\n",
      " [ 5 15 11 13]\n",
      " [15 32 10 27]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.24      0.17      0.20        90\n",
      "meningioma_tumor       0.30      0.36      0.33        91\n",
      "          normal       0.24      0.25      0.24        44\n",
      " pituitary_tumor       0.30      0.32      0.31        84\n",
      "\n",
      "        accuracy                           0.28       309\n",
      "       macro avg       0.27      0.28      0.27       309\n",
      "    weighted avg       0.27      0.28      0.27       309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating, compiling, training, and evaluating a baseline CNN model for multiclass classification\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')  # 4 output units for the 4 classes\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',  # Loss function for multiclass classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "val_loss, val_accuracy = cnn_model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "save_model(cnn_model, 'multiclass_cnn_model.h5')\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = cnn_model.predict(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = val_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=val_generator.class_indices.keys())\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Additional Layers, Filters, and Dropout and Reducing Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - 476s 6s/step - loss: 1.3685 - accuracy: 0.2820 - val_loss: 1.3623 - val_accuracy: 0.2945\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 469s 6s/step - loss: 1.3584 - accuracy: 0.3010 - val_loss: 1.3545 - val_accuracy: 0.4531\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 472s 6s/step - loss: 1.3346 - accuracy: 0.3463 - val_loss: 1.2584 - val_accuracy: 0.4045\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 471s 6s/step - loss: 1.1877 - accuracy: 0.4158 - val_loss: 1.2438 - val_accuracy: 0.4045\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 474s 6s/step - loss: 1.1480 - accuracy: 0.4420 - val_loss: 1.0501 - val_accuracy: 0.4563\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 433s 6s/step - loss: 1.1093 - accuracy: 0.4780 - val_loss: 0.9426 - val_accuracy: 0.6181\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 409s 5s/step - loss: 1.0758 - accuracy: 0.5026 - val_loss: 0.9520 - val_accuracy: 0.5437\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 422s 5s/step - loss: 1.0224 - accuracy: 0.5434 - val_loss: 0.8996 - val_accuracy: 0.5987\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 420s 5s/step - loss: 0.9970 - accuracy: 0.5531 - val_loss: 0.8925 - val_accuracy: 0.5987\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 414s 5s/step - loss: 0.9096 - accuracy: 0.6065 - val_loss: 0.9208 - val_accuracy: 0.6084\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 415s 5s/step - loss: 0.8997 - accuracy: 0.6198 - val_loss: 0.9025 - val_accuracy: 0.6343\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 413s 5s/step - loss: 0.8552 - accuracy: 0.6428 - val_loss: 1.0774 - val_accuracy: 0.5469\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 418s 5s/step - loss: 0.8289 - accuracy: 0.6578 - val_loss: 1.1109 - val_accuracy: 0.5761\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 418s 5s/step - loss: 0.8418 - accuracy: 0.6481 - val_loss: 0.6635 - val_accuracy: 0.7443\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 416s 5s/step - loss: 0.7772 - accuracy: 0.6667 - val_loss: 0.6459 - val_accuracy: 0.7087\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 449s 6s/step - loss: 0.7339 - accuracy: 0.6909 - val_loss: 0.6963 - val_accuracy: 0.7249\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 472s 6s/step - loss: 0.7131 - accuracy: 0.7103 - val_loss: 1.0108 - val_accuracy: 0.6375\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 470s 6s/step - loss: 0.7151 - accuracy: 0.6958 - val_loss: 0.5468 - val_accuracy: 0.7832\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - 469s 6s/step - loss: 0.6758 - accuracy: 0.7273 - val_loss: 1.1494 - val_accuracy: 0.6278\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - 470s 6s/step - loss: 0.6937 - accuracy: 0.7212 - val_loss: 0.7910 - val_accuracy: 0.7087\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - 470s 6s/step - loss: 0.6599 - accuracy: 0.7349 - val_loss: 0.5051 - val_accuracy: 0.8123\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - 445s 6s/step - loss: 0.6586 - accuracy: 0.7382 - val_loss: 0.7283 - val_accuracy: 0.7249\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - 400s 5s/step - loss: 0.6353 - accuracy: 0.7503 - val_loss: 0.5695 - val_accuracy: 0.7508\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - 403s 5s/step - loss: 0.6222 - accuracy: 0.7620 - val_loss: 0.7848 - val_accuracy: 0.7282\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - 402s 5s/step - loss: 0.6089 - accuracy: 0.7612 - val_loss: 0.5496 - val_accuracy: 0.7929\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - 402s 5s/step - loss: 0.5903 - accuracy: 0.7588 - val_loss: 0.6739 - val_accuracy: 0.7476\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5051 - accuracy: 0.8123\n",
      "Validation Loss: 0.5050603747367859\n",
      "Validation Accuracy: 0.8122977614402771\n",
      "10/10 [==============================] - 12s 1s/step\n",
      "Confusion Matrix:\n",
      "[[28 29 13 20]\n",
      " [27 30 13 21]\n",
      " [14 10  4 16]\n",
      " [20 20 21 23]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.31      0.31      0.31        90\n",
      "meningioma_tumor       0.34      0.33      0.33        91\n",
      "          normal       0.08      0.09      0.08        44\n",
      " pituitary_tumor       0.29      0.27      0.28        84\n",
      "\n",
      "        accuracy                           0.28       309\n",
      "       macro avg       0.25      0.25      0.25       309\n",
      "    weighted avg       0.28      0.28      0.28       309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating, compiling, training, and evaluating an enhanced CNN model \n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4, activation='softmax')  \n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.00005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "val_loss, val_accuracy = cnn_model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "save_model(cnn_model, 'enhanced_multiclass_cnn_model.h5')\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = cnn_model.predict(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = val_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=val_generator.class_indices.keys())\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Adding More Layers, Filters, & Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - 700s 9s/step - loss: 2.1091 - accuracy: 0.4388 - val_loss: 2.6698 - val_accuracy: 0.2945\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 600s 8s/step - loss: 1.2651 - accuracy: 0.5568 - val_loss: 2.4654 - val_accuracy: 0.1424\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 588s 8s/step - loss: 0.9778 - accuracy: 0.6162 - val_loss: 1.2940 - val_accuracy: 0.3689\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 584s 7s/step - loss: 0.9296 - accuracy: 0.6222 - val_loss: 2.2204 - val_accuracy: 0.3528\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 579s 7s/step - loss: 0.8849 - accuracy: 0.6493 - val_loss: 1.2936 - val_accuracy: 0.5469\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 579s 7s/step - loss: 0.7994 - accuracy: 0.6683 - val_loss: 1.0702 - val_accuracy: 0.6343\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 581s 7s/step - loss: 0.7428 - accuracy: 0.6933 - val_loss: 1.0667 - val_accuracy: 0.6246\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 582s 7s/step - loss: 0.7354 - accuracy: 0.6962 - val_loss: 0.5742 - val_accuracy: 0.7929\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 578s 7s/step - loss: 0.6991 - accuracy: 0.7147 - val_loss: 0.9380 - val_accuracy: 0.6537\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 590s 8s/step - loss: 0.7007 - accuracy: 0.7184 - val_loss: 0.6546 - val_accuracy: 0.7508\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 582s 7s/step - loss: 0.6751 - accuracy: 0.7261 - val_loss: 0.7779 - val_accuracy: 0.6958\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 578s 7s/step - loss: 0.6529 - accuracy: 0.7422 - val_loss: 0.7582 - val_accuracy: 0.7282\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 585s 7s/step - loss: 0.6073 - accuracy: 0.7596 - val_loss: 0.4836 - val_accuracy: 0.8317\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 581s 7s/step - loss: 0.5955 - accuracy: 0.7511 - val_loss: 1.0786 - val_accuracy: 0.6440\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 579s 7s/step - loss: 0.6070 - accuracy: 0.7539 - val_loss: 0.5843 - val_accuracy: 0.7864\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 626s 8s/step - loss: 0.5783 - accuracy: 0.7620 - val_loss: 0.7197 - val_accuracy: 0.7249\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 646s 8s/step - loss: 0.5385 - accuracy: 0.7846 - val_loss: 0.7294 - val_accuracy: 0.7638\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 645s 8s/step - loss: 0.5204 - accuracy: 0.7903 - val_loss: 0.5435 - val_accuracy: 0.7832\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.4836 - accuracy: 0.8317\n",
      "Validation Loss: 0.48360633850097656\n",
      "Validation Accuracy: 0.8317152261734009\n",
      "10/10 [==============================] - 20s 2s/step\n",
      "Confusion Matrix:\n",
      "[[24 23  7 36]\n",
      " [22 24 19 26]\n",
      " [ 8 15  5 16]\n",
      " [17 26 13 28]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.34      0.27      0.30        90\n",
      "meningioma_tumor       0.27      0.26      0.27        91\n",
      "          normal       0.11      0.11      0.11        44\n",
      " pituitary_tumor       0.26      0.33      0.29        84\n",
      "\n",
      "        accuracy                           0.26       309\n",
      "       macro avg       0.25      0.24      0.24       309\n",
      "    weighted avg       0.27      0.26      0.26       309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating, compiling, training, and evaluating enhanced CNN model with more layers, increased filters, and batch normalization \n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4, activation='softmax')  \n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.00005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "val_loss, val_accuracy = cnn_model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "save_model(cnn_model, 'enhanced_multiclass_cnn_with_bn.h5')\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = cnn_model.predict(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = val_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=val_generator.class_indices.keys())\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Multiple Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 20s 2s/step - loss: 0.4235 - accuracy: 0.8558\n",
      "Test Loss: 0.4234536588191986\n",
      "Test Accuracy: 0.8557692170143127\n",
      "10/10 [==============================] - 19s 2s/step\n",
      "Confusion Matrix:\n",
      "[[26 17 12 36]\n",
      " [27 26 15 24]\n",
      " [13 14  8  9]\n",
      " [19 28 11 27]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.31      0.29      0.30        91\n",
      "meningioma_tumor       0.31      0.28      0.29        92\n",
      "          normal       0.17      0.18      0.18        44\n",
      " pituitary_tumor       0.28      0.32      0.30        85\n",
      "\n",
      "        accuracy                           0.28       312\n",
      "       macro avg       0.27      0.27      0.27       312\n",
      "    weighted avg       0.28      0.28      0.28       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading, and evaluating my final multiple classification model on the test data\n",
    "\n",
    "cnn_model = load_model('enhanced_multiclass_cnn_with_bn.h5')\n",
    "\n",
    "test_loss, test_accuracy = cnn_model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "test_generator.reset()\n",
    "predictions = cnn_model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=test_generator.class_indices.keys())\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
